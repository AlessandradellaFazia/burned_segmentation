{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from pathlib import Path \n",
    "from mmengine import Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\EDELLAA6Y\\\\multitask\\\\refactoring2\\\\burned\\\\notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def resize(input, size=None, scale_factor=None, mode=\"nearest\", align_corners=None, warning=True):\n",
    "    if warning:\n",
    "        if size is not None and align_corners:\n",
    "            input_h, input_w = tuple(int(x) for x in input.shape[2:])\n",
    "            output_h, output_w = tuple(int(x) for x in size)\n",
    "            if output_h > input_h or output_w > output_h:\n",
    "                if (\n",
    "                    (output_h > 1 and output_w > 1 and input_h > 1 and input_w > 1)\n",
    "                    and (output_h - 1) % (input_h - 1)\n",
    "                    and (output_w - 1) % (input_w - 1)\n",
    "                ):\n",
    "                    warnings.warn(\n",
    "                        f\"When align_corners={align_corners}, \"\n",
    "                        \"the output would more aligned if \"\n",
    "                        f\"input size {(input_h, input_w)} is `x+1` and \"\n",
    "                        f\"out size {(output_h, output_w)} is `nx+1`\"\n",
    "                    )\n",
    "    return F.interpolate(input, size, scale_factor, mode, align_corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.models.segmentors.encoder_decoder import EncoderDecoder\n",
    "from mmseg.registry import MODELS\n",
    "from mmseg.utils import OptSampleList\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "@MODELS.register_module()\n",
    "class CustomEncoderDecoder(EncoderDecoder):\n",
    "    def _forward(self, inputs: Tensor, data_samples: OptSampleList = None) -> Tensor:\n",
    "        \"\"\"Network forward process.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): Inputs with shape (N, C, H, W).\n",
    "            data_samples (List[:obj:`SegDataSample`]): The seg\n",
    "                data samples. It usually includes information such\n",
    "                as `metainfo` and `gt_sem_seg`.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Forward output of model without any post-processes.\n",
    "        \"\"\"\n",
    "        x = self.extract_feat(inputs)\n",
    "        feat = self.decode_head(x)\n",
    "        out = self.decode_head.cls_seg(feat)\n",
    "        out = F.interpolate(out, size=inputs.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        if self.decode_head.has_aux_output():\n",
    "            aux = self.decode_head.cls_seg_aux(feat)\n",
    "            aux = F.interpolate(aux, size=inputs.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "            return out, aux\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import torch.nn as nn\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmseg.registry import MODELS\n",
    "import warnings\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "from mmengine.model import BaseModule\n",
    "from mmseg.models.builder import build_loss\n",
    "from mmseg.structures import build_pixel_sampler\n",
    "\n",
    "\n",
    "class CustomBaseDecodeHead(BaseModule, metaclass=ABCMeta):\n",
    "    \"\"\"Custom class for BaseDecodeHead to simply remove the loss from the head.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        channels,\n",
    "        *,\n",
    "        num_classes,\n",
    "        aux_classes=None,\n",
    "        aux_factor=None,\n",
    "        out_channels=None,\n",
    "        threshold=None,\n",
    "        dropout_ratio=0.1,\n",
    "        conv_cfg=None,\n",
    "        norm_cfg=None,\n",
    "        act_cfg=dict(type=\"ReLU\"),\n",
    "        in_index=-1,\n",
    "        input_transform=None,\n",
    "        loss_decode=None,\n",
    "        ignore_index=255,\n",
    "        sampler=None,\n",
    "        align_corners=False,\n",
    "        init_cfg=dict(type=\"Normal\", std=0.01, override=dict(name=\"conv_seg\")),\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        self._init_inputs(in_channels, in_index, input_transform)\n",
    "        self.channels = channels\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.in_index = in_index\n",
    "\n",
    "        self.ignore_index = ignore_index\n",
    "        self.align_corners = align_corners\n",
    "\n",
    "        if out_channels is None:\n",
    "            if num_classes == 2:\n",
    "                warnings.warn(\n",
    "                    \"For binary segmentation, we suggest using\"\n",
    "                    \"`out_channels = 1` to define the output\"\n",
    "                    \"channels of segmentor, and use `threshold`\"\n",
    "                    \"to convert `seg_logits` into a prediction\"\n",
    "                    \"applying a threshold\"\n",
    "                )\n",
    "            out_channels = num_classes\n",
    "\n",
    "        if out_channels != num_classes and out_channels != 1:\n",
    "            raise ValueError(\n",
    "                \"out_channels should be equal to num_classes,\"\n",
    "                \"except binary segmentation set out_channels == 1 and\"\n",
    "                f\"num_classes == 2, but got out_channels={out_channels}\"\n",
    "                f\"and num_classes={num_classes}\"\n",
    "            )\n",
    "\n",
    "        if out_channels == 1 and threshold is None:\n",
    "            threshold = 0.5\n",
    "            warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.5\")\n",
    "        self.num_classes = num_classes\n",
    "        self.out_channels = out_channels\n",
    "        self.threshold = threshold\n",
    "\n",
    "        if isinstance(loss_decode, dict):\n",
    "            self.loss_decode = build_loss(loss_decode)\n",
    "        elif isinstance(loss_decode, (list, tuple)):\n",
    "            self.loss_decode = nn.ModuleList()\n",
    "            for loss in loss_decode:\n",
    "                self.loss_decode.append(build_loss(loss))\n",
    "        else:\n",
    "            warnings.warn(\"Loss not instantiated, use manual .forward() calls\")\n",
    "            self.loss_decode = None\n",
    "\n",
    "        if sampler is not None:\n",
    "            self.sampler = build_pixel_sampler(sampler, context=self)\n",
    "        else:\n",
    "            self.sampler = None\n",
    "\n",
    "        self.conv_seg = nn.Conv2d(channels, self.out_channels, kernel_size=1)\n",
    "        if aux_classes is not None:\n",
    "            self.conv_seg_aux = nn.Conv2d(channels, aux_classes, kernel_size=1)\n",
    "            self.aux_factor = aux_factor\n",
    "        else:\n",
    "            self.conv_seg_aux = None\n",
    "        if dropout_ratio > 0:\n",
    "            self.dropout = nn.Dropout2d(dropout_ratio)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def _init_inputs(self, in_channels, in_index, input_transform):\n",
    "        \"\"\"Check and initialize input transforms.\n",
    "\n",
    "        The in_channels, in_index and input_transform must match.\n",
    "        Specifically, when input_transform is None, only single feature map\n",
    "        will be selected. So in_channels and in_index must be of type int.\n",
    "        When input_transform\n",
    "\n",
    "        Args:\n",
    "            in_channels (int|Sequence[int]): Input channels.\n",
    "            in_index (int|Sequence[int]): Input feature index.\n",
    "            input_transform (str|None): Transformation type of input features.\n",
    "                Options: 'resize_concat', 'multiple_select', None.\n",
    "                'resize_concat': Multiple feature maps will be resize to the\n",
    "                    same size as first one and than concat together.\n",
    "                    Usually used in FCN head of HRNet.\n",
    "                'multiple_select': Multiple feature maps will be bundle into\n",
    "                    a list and passed into decode head.\n",
    "                None: Only one select feature map is allowed.\n",
    "        \"\"\"\n",
    "\n",
    "        if input_transform is not None:\n",
    "            assert input_transform in [\"resize_concat\", \"multiple_select\"]\n",
    "        self.input_transform = input_transform\n",
    "        self.in_index = in_index\n",
    "        if input_transform is not None:\n",
    "            assert isinstance(in_channels, (list, tuple))\n",
    "            assert isinstance(in_index, (list, tuple))\n",
    "            assert len(in_channels) == len(in_index)\n",
    "            if input_transform == \"resize_concat\":\n",
    "                self.in_channels = sum(in_channels)\n",
    "            else:\n",
    "                self.in_channels = in_channels\n",
    "        else:\n",
    "            assert isinstance(in_channels, int)\n",
    "            assert isinstance(in_index, int)\n",
    "            self.in_channels = in_channels\n",
    "\n",
    "    def _transform_inputs(self, inputs):\n",
    "        \"\"\"Transform inputs for decoder.\n",
    "\n",
    "        Args:\n",
    "            inputs (list[Tensor]): List of multi-level img features.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The transformed inputs\n",
    "        \"\"\"\n",
    "        if self.input_transform == \"resize_concat\":\n",
    "            inputs = [inputs[i] for i in self.in_index]\n",
    "            upsampled_inputs = [\n",
    "                resize(input=x, size=inputs[0].shape[2:], mode=\"bilinear\", align_corners=self.align_corners)\n",
    "                for x in inputs\n",
    "            ]\n",
    "            inputs = torch.cat(upsampled_inputs, dim=1)\n",
    "        elif self.input_transform == \"multiple_select\":\n",
    "            inputs = [inputs[i] for i in self.in_index]\n",
    "        else:\n",
    "            inputs = inputs[self.in_index]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, inputs, return_feat: bool = False):\n",
    "        \"\"\"Placeholder of forward function.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def has_aux_output(self):\n",
    "        \"\"\"Whether the head has auxiliary output.\"\"\"\n",
    "        return self.conv_seg_aux is not None\n",
    "\n",
    "    def cls_seg(self, feat: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Classify each pixel.\"\"\"\n",
    "        if self.dropout is not None:\n",
    "            feat = self.dropout(feat)\n",
    "        output = self.conv_seg(feat)\n",
    "        return output\n",
    "\n",
    "    def cls_seg_aux(self, feat: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Classify each pixel.\"\"\"\n",
    "        if self.dropout is not None:\n",
    "            feat = self.dropout(feat)\n",
    "        output = self.conv_seg_aux(feat)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PPM(nn.ModuleList):\n",
    "    \"\"\"Pooling Pyramid Module used in PSPNet.\n",
    "\n",
    "    Args:\n",
    "        pool_scales (tuple[int]): Pooling scales used in Pooling Pyramid\n",
    "            Module.\n",
    "        in_channels (int): Input channels.\n",
    "        channels (int): Channels after modules, before conv_seg.\n",
    "        conv_cfg (dict|None): Config of conv layers.\n",
    "        norm_cfg (dict|None): Config of norm layers.\n",
    "        act_cfg (dict): Config of activation layers.\n",
    "        align_corners (bool): align_corners argument of F.interpolate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_scales, in_channels, channels, conv_cfg, norm_cfg, act_cfg, align_corners, **kwargs):\n",
    "        super().__init__()\n",
    "        self.pool_scales = pool_scales\n",
    "        self.align_corners = align_corners\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        for pool_scale in pool_scales:\n",
    "            self.append(\n",
    "                nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(pool_scale),\n",
    "                    ConvModule(\n",
    "                        self.in_channels,\n",
    "                        self.channels,\n",
    "                        1,\n",
    "                        conv_cfg=self.conv_cfg,\n",
    "                        norm_cfg=self.norm_cfg,\n",
    "                        act_cfg=self.act_cfg,\n",
    "                        **kwargs,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        ppm_outs = []\n",
    "        for ppm in self:\n",
    "            ppm_out = ppm(x)\n",
    "            upsampled_ppm_out = resize(ppm_out, size=x.size()[2:], mode=\"bilinear\", align_corners=self.align_corners)\n",
    "            ppm_outs.append(upsampled_ppm_out)\n",
    "        return ppm_outs\n",
    "\n",
    "\n",
    "@MODELS.register_module()\n",
    "class CustomUPerHead(CustomBaseDecodeHead):\n",
    "    \"\"\"Unified Perceptual Parsing for Scene Understanding.\n",
    "\n",
    "    This head is the implementation of `UPerNet\n",
    "    <https://arxiv.org/abs/1807.10221>`_.\n",
    "\n",
    "    Args:\n",
    "        pool_scales (tuple[int]): Pooling scales used in Pooling Pyramid\n",
    "            Module applied on the last feature. Default: (1, 2, 3, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_scales=(1, 2, 3, 6), **kwargs):\n",
    "        super().__init__(input_transform=\"multiple_select\", **kwargs)\n",
    "        # PSP Module\n",
    "        self.psp_modules = PPM(\n",
    "            pool_scales,\n",
    "            self.in_channels[-1],\n",
    "            self.channels,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "            align_corners=self.align_corners,\n",
    "        )\n",
    "        self.bottleneck = ConvModule(\n",
    "            self.in_channels[-1] + len(pool_scales) * self.channels,\n",
    "            self.channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "        # FPN Module\n",
    "        self.lateral_convs = nn.ModuleList()\n",
    "        self.fpn_convs = nn.ModuleList()\n",
    "        for in_channels in self.in_channels[:-1]:  # skip the top layer\n",
    "            l_conv = ConvModule(\n",
    "                in_channels,\n",
    "                self.channels,\n",
    "                1,\n",
    "                conv_cfg=self.conv_cfg,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg,\n",
    "                inplace=False,\n",
    "            )\n",
    "            fpn_conv = ConvModule(\n",
    "                self.channels,\n",
    "                self.channels,\n",
    "                3,\n",
    "                padding=1,\n",
    "                conv_cfg=self.conv_cfg,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg,\n",
    "                inplace=False,\n",
    "            )\n",
    "            self.lateral_convs.append(l_conv)\n",
    "            self.fpn_convs.append(fpn_conv)\n",
    "\n",
    "        self.fpn_bottleneck = ConvModule(\n",
    "            len(self.in_channels) * self.channels,\n",
    "            self.channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "\n",
    "    def psp_forward(self, inputs):\n",
    "        \"\"\"Forward function of PSP module.\"\"\"\n",
    "        x = inputs[-1]\n",
    "        psp_outs = [x]\n",
    "        psp_outs.extend(self.psp_modules(x))\n",
    "        psp_outs = torch.cat(psp_outs, dim=1)\n",
    "        output = self.bottleneck(psp_outs)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _forward_feature(self, inputs):\n",
    "        \"\"\"Forward function for feature maps before classifying each pixel with\n",
    "        ``self.cls_seg`` fc.\n",
    "\n",
    "        Args:\n",
    "            inputs (list[Tensor]): List of multi-level img features.\n",
    "\n",
    "        Returns:\n",
    "            feats (Tensor): A tensor of shape (batch_size, self.channels,\n",
    "                H, W) which is feature map for last layer of decoder head.\n",
    "        \"\"\"\n",
    "        inputs = self._transform_inputs(inputs)\n",
    "\n",
    "        # build laterals\n",
    "        laterals = [lateral_conv(inputs[i]) for i, lateral_conv in enumerate(self.lateral_convs)]\n",
    "\n",
    "        laterals.append(self.psp_forward(inputs))\n",
    "\n",
    "        # build top-down path\n",
    "        used_backbone_levels = len(laterals)\n",
    "        for i in range(used_backbone_levels - 1, 0, -1):\n",
    "            prev_shape = laterals[i - 1].shape[2:]\n",
    "            laterals[i - 1] = laterals[i - 1] + resize(\n",
    "                laterals[i], size=prev_shape, mode=\"bilinear\", align_corners=self.align_corners\n",
    "            )\n",
    "\n",
    "        # build outputs\n",
    "        fpn_outs = [self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels - 1)]\n",
    "        # append psp feature\n",
    "        fpn_outs.append(laterals[-1])\n",
    "\n",
    "        for i in range(used_backbone_levels - 1, 0, -1):\n",
    "            fpn_outs[i] = resize(\n",
    "                fpn_outs[i], size=fpn_outs[0].shape[2:], mode=\"bilinear\", align_corners=self.align_corners\n",
    "            )\n",
    "        fpn_outs = torch.cat(fpn_outs, dim=1)\n",
    "        feats = self.fpn_bottleneck(fpn_outs)\n",
    "        return feats\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        return self._forward_feature(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.registry import MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = Path(\"..\\configs\\single\\pretrained\\ems_upernet-rn50_single_50ep.py\")\n",
    "config = Config.fromfile(cfg_path)\n",
    "model_config = config[\"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\mmseg\\models\\backbones\\resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:71: UserWarning: threshold is not defined for binary, and defaultsto 0.5\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.5\")\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:83: UserWarning: Loss not instantiated, use manual .forward() calls\n",
      "  warnings.warn(\"Loss not instantiated, use manual .forward() calls\")\n"
     ]
    }
   ],
   "source": [
    "resnet = MODELS.build(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEncoderDecoder(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/mmseg_rn50_ss4eo.pth'}\n",
       "  (decode_head): CustomUPerHead(\n",
       "    (conv_seg): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (psp_modules): PPM(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): ConvModule(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-2): 3 x ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_bottleneck): ConvModule(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomUPerHead(\n",
       "  (conv_seg): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "  (psp_modules): PPM(\n",
       "    (0): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=2)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=3)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=6)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): ConvModule(\n",
       "    (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_convs): ModuleList(\n",
       "    (0-2): 3 x ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_bottleneck): ConvModule(\n",
       "    (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       ")\n",
       "init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.decode_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics import F1Score, JaccardIndex\n",
    "from mmseg.registry import MODELS\n",
    "\n",
    "class BaseModule(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        tiler: Optional[Callable] = None,\n",
    "        predict_callback: Optional[Callable] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = MODELS.build(config)\n",
    "        self.model.cfg = config\n",
    "        self.tiler = tiler\n",
    "        self.predict_callback = predict_callback\n",
    "        self.train_metrics = nn.ModuleDict(\n",
    "            {\n",
    "                \"train_f1\": F1Score(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "                \"train_iou\": JaccardIndex(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "            }\n",
    "        )\n",
    "        self.val_metrics = nn.ModuleDict(\n",
    "            {\n",
    "                \"val_f1\": F1Score(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "                \"val_iou\": JaccardIndex(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "            }\n",
    "        )\n",
    "        self.test_metrics = nn.ModuleDict(\n",
    "            {\n",
    "                \"test_f1\": F1Score(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "                \"test_iou\": JaccardIndex(task=\"binary\", ignore_index=255, average=\"macro\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def init_pretrained(self) -> None:\n",
    "        assert self.model.cfg, \"Model config is not set\"\n",
    "        config = self.model.cfg.backbone\n",
    "        if \"pretrained\" not in config or config.pretrained is None:\n",
    "            warnings.warn(\"No pretrained weights are specified\")\n",
    "            return\n",
    "        self.model.backbone.load_state_dict(torch.load(config.pretrained), strict=False)\n",
    "        for param in self.model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        return AdamW(self.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "class SingleTaskModule(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        tiler: Callable[..., Any] | None = None,\n",
    "        predict_callback: Callable[..., Any] | None = None,\n",
    "        loss: str = \"bce\",\n",
    "    ):\n",
    "        super().__init__(config, tiler, predict_callback)\n",
    "        if loss == \"bce\":\n",
    "            self.criterion_decode = SoftBCEWithLogitsLoss(ignore_index=255, pos_weight=torch.tensor(3.0))\n",
    "        else:\n",
    "            self.criterion_decode = DiceLoss(mode=\"binary\", from_logits=True, ignore_index=255)\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        x = batch[\"S2L2A\"]\n",
    "        y_del = batch[\"DEL\"]\n",
    "\n",
    "        # lc = batch[\"ESA_LC\"]\n",
    "        # x = torch.cat([x, lc.unsqueeze(1)], dim=1)\n",
    "        decode_out = self.model(x)\n",
    "        loss_decode = self.criterion_decode(decode_out.squeeze(1), y_del.float())\n",
    "        loss = loss_decode\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        for metric_name, metric in self.train_metrics.items():\n",
    "            metric(decode_out.squeeze(1), y_del.float())\n",
    "            self.log(metric_name, metric, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int):\n",
    "        x = batch[\"S2L2A\"]\n",
    "        y_del = batch[\"DEL\"]\n",
    "        # lc = batch[\"ESA_LC\"]\n",
    "        # x = torch.cat([x, lc.unsqueeze(1)], dim=1)\n",
    "        decode_out = self.model(x)\n",
    "        loss_decode = self.criterion_decode(decode_out.squeeze(1), y_del.float())\n",
    "        loss = loss_decode\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        for metric_name, metric in self.val_metrics.items():\n",
    "            metric(decode_out.squeeze(1), y_del.float())\n",
    "            self.log(metric_name, metric, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int):\n",
    "        x = batch[\"S2L2A\"]\n",
    "        y_del = batch[\"DEL\"]\n",
    "        # lc = batch[\"ESA_LC\"]\n",
    "        # x = torch.cat([x, lc.unsqueeze(1)], dim=1)\n",
    "        decode_out = self.model(x)\n",
    "        loss_decode = self.criterion_decode(decode_out.squeeze(1), y_del.float())\n",
    "        loss = loss_decode\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, logger=True)\n",
    "        for metric_name, metric in self.test_metrics.items():\n",
    "            metric(decode_out.squeeze(1), y_del.float())\n",
    "            self.log(metric_name, metric, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        full_image = batch[\"S2L2A\"]\n",
    "\n",
    "        def callback(batch: Any):\n",
    "            del_out = self.model(batch)  # [b, 1, h, w]\n",
    "            return del_out.squeeze(1)  # [b, h, w]\n",
    "\n",
    "        full_pred = self.tiler(full_image[0], callback=callback)\n",
    "        batch[\"pred\"] = torch.sigmoid(full_pred)\n",
    "        return batch\n",
    "\n",
    "    def on_predict_batch_end(self, outputs: Any | None, batch: Any, batch_idx: int, dataloader_idx: int) -> None:\n",
    "        self.predict_callback(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\mmseg\\models\\backbones\\resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:71: UserWarning: threshold is not defined for binary, and defaultsto 0.5\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.5\")\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:83: UserWarning: Loss not instantiated, use manual .forward() calls\n",
      "  warnings.warn(\"Loss not instantiated, use manual .forward() calls\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SoftBCEWithLogitsLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTaskModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m module\u001b[38;5;241m.\u001b[39minit_pretrained()\n",
      "Cell \u001b[1;32mIn[20], line 65\u001b[0m, in \u001b[0;36mSingleTaskModule.__init__\u001b[1;34m(self, config, tiler, predict_callback, loss)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config, tiler, predict_callback)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbce\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_decode \u001b[38;5;241m=\u001b[39m \u001b[43mSoftBCEWithLogitsLoss\u001b[49m(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m, pos_weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m3.0\u001b[39m))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_decode \u001b[38;5;241m=\u001b[39m DiceLoss(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SoftBCEWithLogitsLoss' is not defined"
     ]
    }
   ],
   "source": [
    "module = SingleTaskModule(model_config, loss = \"bce\")\n",
    "module.init_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\mmseg\\models\\backbones\\resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:71: UserWarning: threshold is not defined for binary, and defaultsto 0.5\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.5\")\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:83: UserWarning: Loss not instantiated, use manual .forward() calls\n",
      "  warnings.warn(\"Loss not instantiated, use manual .forward() calls\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.shape: torch.Size([2, 12, 512, 512])\n",
      "y.shape: torch.Size([2, 1, 512, 512])\n",
      "backbone res: [torch.Size([2, 256, 128, 128]), torch.Size([2, 512, 64, 64]), torch.Size([2, 1024, 32, 32]), torch.Size([2, 2048, 16, 16])]\n",
      "feat: torch.Size([2, 512, 128, 128])\n",
      "out: torch.Size([2, 1, 128, 128])\n",
      "out: torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "cfg_path = Path(\"..\\configs\\single\\pretrained\\ems_upernet-rn50_single_50ep.py\")\n",
    "config = Config.fromfile(cfg_path)\n",
    "model_config = config[\"model\"]\n",
    "resnet = MODELS.build(model_config)\n",
    "x = torch.randn(2,12,512,512)\n",
    "y = resnet(x)\n",
    "print()\n",
    "print(\"x.shape:\",x.shape)\n",
    "print(\"y.shape:\",y.shape)\n",
    "\n",
    "xb = resnet.backbone(x)\n",
    "print(\"backbone res:\",[xbi.shape for xbi in xb])\n",
    "feat = resnet.decode_head(xb)\n",
    "print(\"feat:\",feat.shape)\n",
    "out = resnet.decode_head.cls_seg(feat)\n",
    "print(\"out:\",out.shape)\n",
    "out = F.interpolate(out, size=x.shape[2:], mode=\"bilinear\", align_corners=True) #2,1,512,512\n",
    "print(\"out:\",out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:71: UserWarning: threshold is not defined for binary, and defaultsto 0.5\n",
      "  warnings.warn(\"threshold is not defined for binary, and defaults\" \"to 0.5\")\n",
      "C:\\Users\\EDELLAA6Y\\AppData\\Local\\Temp\\ipykernel_2884\\575014093.py:83: UserWarning: Loss not instantiated, use manual .forward() calls\n",
      "  warnings.warn(\"Loss not instantiated, use manual .forward() calls\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.shape: torch.Size([2, 12, 512, 512])\n",
      "y.shape: torch.Size([2, 1, 512, 512])\n",
      "backbone res: [torch.Size([2, 96, 128, 128]), torch.Size([2, 192, 64, 64]), torch.Size([2, 384, 32, 32]), torch.Size([2, 768, 16, 16])]\n",
      "feat: torch.Size([2, 512, 128, 128])\n",
      "out: torch.Size([2, 1, 128, 128])\n",
      "out: torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "cfg_path = Path(\"..\\configs\\single\\pretrained\\ems_upernet-rn50_single_50ep_copy.py\")\n",
    "config = Config.fromfile(cfg_path)\n",
    "model_config = config[\"model\"]\n",
    "resnet = MODELS.build(model_config)\n",
    "x = torch.randn(2,12,512,512)\n",
    "y = resnet(x)\n",
    "print()\n",
    "print(\"x.shape:\",x.shape)\n",
    "print(\"y.shape:\",y.shape)\n",
    "\n",
    "xb = resnet.backbone(x)\n",
    "print(\"backbone res:\",[xbi.shape for xbi in xb])\n",
    "feat = resnet.decode_head(xb)\n",
    "print(\"feat:\",feat.shape)\n",
    "out = resnet.decode_head.cls_seg(feat)\n",
    "print(\"out:\",out.shape)\n",
    "out = F.interpolate(out, size=x.shape[2:], mode=\"bilinear\", align_corners=True) #2,1,512,512\n",
    "print(\"out:\",out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.shape: torch.Size([2, 12, 512, 512])\n",
      "y.shape: torch.Size([2, 1, 128, 128])\n",
      "backbone res: [torch.Size([2, 96, 128, 128]), torch.Size([2, 192, 64, 64]), torch.Size([2, 384, 32, 32]), torch.Size([2, 768, 16, 16])]\n",
      "feat: torch.Size([2, 1, 128, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 512, 1, 1], expected input[2, 1, 128, 128] to have 512 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m feat \u001b[38;5;241m=\u001b[39m swin\u001b[38;5;241m.\u001b[39mdecode_head(xb)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeat:\u001b[39m\u001b[38;5;124m\"\u001b[39m,feat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 15\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mswin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout:\u001b[39m\u001b[38;5;124m\"\u001b[39m,out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     17\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(out, size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#2,1,512,512\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\mmseg\\models\\decode_heads\\decode_head.py:244\u001b[0m, in \u001b[0;36mBaseDecodeHead.cls_seg\u001b[1;34m(self, feat)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(feat)\n\u001b[1;32m--> 244\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EDELLAA6Y\\multitask\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 512, 1, 1], expected input[2, 1, 128, 128] to have 512 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "cfg_path = Path(\"..\\configs\\single\\pretrained\\swin\\swin2.py\")\n",
    "config = Config.fromfile(cfg_path)\n",
    "model_config = config[\"model\"]\n",
    "swin = MODELS.build(model_config)\n",
    "x = torch.randn(2,12,512,512)\n",
    "y = swin(x)\n",
    "print()\n",
    "print(\"x.shape:\",x.shape)\n",
    "print(\"y.shape:\",y.shape)\n",
    "\n",
    "xb = swin.backbone(x)\n",
    "print(\"backbone res:\",[xbi.shape for xbi in xb])\n",
    "feat = swin.decode_head(xb)\n",
    "print(\"feat:\",feat.shape)\n",
    "out = swin.decode_head.cls_seg(feat)\n",
    "print(\"out:\",out.shape)\n",
    "out = F.interpolate(out, size=x.shape[2:], mode=\"bilinear\", align_corners=True) #2,1,512,512\n",
    "print(\"out:\",out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEncoderDecoder(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/mmseg_rn50_ss4eo.pth'}\n",
       "  (decode_head): CustomUPerHead(\n",
       "    (conv_seg): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (psp_modules): PPM(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): ConvModule(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-2): 3 x ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_bottleneck): ConvModule(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UPerHead(\n",
       "  input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "  (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "  (conv_seg): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "  (psp_modules): PPM(\n",
       "    (0): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=2)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=3)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=6)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): ConvModule(\n",
       "    (conv): Conv2d(2816, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_convs): ModuleList(\n",
       "    (0-2): 3 x ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_bottleneck): ConvModule(\n",
       "    (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       ")\n",
       "init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin.decode_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseDecodeHead.cls_seg of UPerHead(\n",
       "  input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "  (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "  (conv_seg): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "  (psp_modules): PPM(\n",
       "    (0): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=2)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=3)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=6)\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): ConvModule(\n",
       "    (conv): Conv2d(2816, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): ConvModule(\n",
       "      (conv): Conv2d(96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (1): ConvModule(\n",
       "      (conv): Conv2d(192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "    (2): ConvModule(\n",
       "      (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_convs): ModuleList(\n",
       "    (0-2): 3 x ConvModule(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fpn_bottleneck): ConvModule(\n",
       "    (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU(inplace=True)\n",
       "  )\n",
       ")\n",
       "init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin.decode_head.cls_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
